import streamlit as st
import polars as pl
import os
import time
from datetime import datetime

st.set_page_config(page_title="AI Assistant", page_icon="ü§ñ", layout="wide")

st.title("ü§ñ AI Data Assistant (Buffer Layer)")
st.caption("M√¥ ph·ªèng l·ªõp ƒë·ªám AI: Ti·∫øp nh·∫≠n Query -> Ph√¢n t√≠ch Intent -> Truy xu·∫•t d·ªØ li·ªáu.")

# Path config
DATA_PATH = "../scrape_tool/exports/Master_PPC_Data.parquet"
SNAPSHOT_DIR = "../scrape_tool/exports/snapshots"
os.makedirs(SNAPSHOT_DIR, exist_ok=True)

# --- SIDEBAR CONTROLS ---
with st.sidebar:
    st.header("‚öôÔ∏è AI Simulation Control")
    st.info("V√¨ ch∆∞a c√≥ API, c√°c t√πy ch·ªçn n√†y gi√∫p m√¥ ph·ªèng quy·∫øt ƒë·ªãnh c·ªßa AI.")
    
    force_context = st.checkbox("üîí Kh√≥a Context (Force Follow-up)", value=False, 
                                help="N·∫øu b·∫≠t, AI s·∫Ω lu√¥n query tr√™n k·∫øt qu·∫£ t√¨m ki·∫øm tr∆∞·ªõc ƒë√≥ thay v√¨ Master Data.")
    
    st.divider()
    if st.button("üóëÔ∏è Clear History"):
        st.session_state.messages = [{"role": "assistant", "content": "Tech Lead ƒë√¢y. Data ƒë√£ s·∫µn s√†ng."}]
        st.session_state.last_active_df = None
        st.rerun()

# --- DATA LOADER ---
@st.cache_data
def load_data():
    if os.path.exists(DATA_PATH):
        try:
            return pl.read_parquet(DATA_PATH)
        except:
            return None
    return None

master_df = load_data()

# --- STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_active_df" not in st.session_state:
    st.session_state.last_active_df = None

# --- AI ROUTER LOGIC (MOCK) ---
def simulate_ai_router(prompt, has_history):
    """
    Gi·∫£ l·∫≠p logic c·ªßa AI ƒë·ªÉ x√°c ƒë·ªãnh Intent (M·ª•c ƒë√≠ch) c·ªßa user.
    Output: (is_followup, reason)
    """
    # 1. Manual Override t·ª´ Sidebar
    if force_context:
        if has_history:
            return True, "User √©p bu·ªôc d√πng Context c≈© (Sidebar setting)."
        else:
            return False, "User √©p context nh∆∞ng ch∆∞a c√≥ l·ªãch s·ª≠ -> Bu·ªôc d√πng Master Data."

    # 2. Mock Logic (S·∫Ω thay b·∫±ng LLM API Call sau n√†y)
    # Prompt cho LLM th·ª±c t·∫ø s·∫Ω l√†:
    # "User h·ªèi: '{prompt}'. L·ªãch s·ª≠ tr∆∞·ªõc ƒë√≥ c√≥ data kh√¥ng? N·∫øu c√≥, c√¢u n√†y l√† l·ªçc ti·∫øp hay h·ªèi m·ªõi? Tr·∫£ v·ªÅ JSON."
    
    prompt_lower = prompt.lower()
    keywords_followup = ["trong ƒë√≥", "l·ªçc ra", "s·∫Øp x·∫øp", "sort", "filter", "l·∫•y", "c√≤n l·∫°i"]
    
    # Logic t·∫°m th·ªùi (v·∫´n d√πng keyword nh∆∞ng minh b·∫°ch h√≥a output)
    if has_history and any(w in prompt_lower for w in keywords_followup):
        return True, f"AI ph√°t hi·ªán t·ª´ kh√≥a n·ªëi ti·∫øp: {[w for w in keywords_followup if w in prompt_lower]}"
    
    return False, "AI nh·∫≠n ƒë·ªãnh ƒë√¢y l√† c√¢u h·ªèi m·ªõi (New Topic)."

# --- UI RENDER HISTORY ---
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "data" in message:
            df_display = message["data"]
            st.dataframe(df_display, height=200)
            
            # Action Buttons
            c1, c2 = st.columns([1, 4])
            with c1:
                csv = df_display.to_csv(index=False).encode('utf-8')
                st.download_button("üì• T·∫£i CSV", csv, f"result_{idx}.csv", "text/csv", key=f"dl_{idx}")
            with c2:
                if st.button("üíæ Snapshot PBI", key=f"snap_{idx}"):
                    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                    path = os.path.join(SNAPSHOT_DIR, f"snapshot_{ts}.parquet")
                    pl.from_pandas(df_display).write_parquet(path)
                    st.toast(f"‚úÖ Saved: {path}")

# --- CHAT INPUT ---
if prompt := st.chat_input("H·ªèi g√¨ ƒëi bro..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        msg_placeholder = st.empty()
        status_placeholder = st.empty() # Ch·ªó hi·ªÉn th·ªã suy nghƒ© c·ªßa AI
        
        msg_placeholder.markdown("‚è≥ *AI ƒëang ph√¢n t√≠ch Intent...*")
        time.sleep(0.5)

        # 1. Router Phase
        has_history = st.session_state.last_active_df is not None
        is_followup, reason = simulate_ai_router(prompt, has_history)
        
        # Hi·ªÉn th·ªã suy nghƒ© (Transparency)
        status_placeholder.info(f"üß† **Thinking:** {reason}")
        
        # 2. Data Selection Phase
        if is_followup:
            source_df = pl.from_pandas(st.session_state.last_active_df)
            source_name = "Context (K·∫øt qu·∫£ tr∆∞·ªõc)"
        else:
            source_df = master_df
            source_name = "Master Data (G·ªëc)"

        # 3. Execution Phase (Mock Query)
        response_text = ""
        response_df = None
        
        if source_df is not None:
            try:
                prompt_lower = prompt.lower()
                # Mock Query Logic
                if "doanh thu" in prompt_lower or "revenue" in prompt_lower:
                    if "Revenue (Actual)" in source_df.columns:
                        response_df = source_df.sort("Revenue (Actual)", descending=True).head(10).to_pandas()
                        response_text = f"Top 10 Doanh thu t·ª´ **{source_name}**:"
                    else:
                        response_text = "D·ªØ li·ªáu hi·ªán t·∫°i kh√¥ng c√≥ c·ªôt Revenue."
                        
                elif "ƒë·ªët ti·ªÅn" in prompt_lower or "bleeding" in prompt_lower:
                    response_df = source_df.filter(
                        (pl.col("Unit sold (Actual)") == 0) & 
                        (pl.col("Ads Spend (Actual)") > 30)
                    ).to_pandas()
                    response_text = f"Danh s√°ch Bleeding t·ª´ **{source_name}**:"
                
                elif "l·ªçc" in prompt_lower: # Mock filter
                     response_df = source_df.head(5).to_pandas()
                     response_text = f"ƒê√£ l·ªçc m·∫´u 5 d√≤ng t·ª´ **{source_name}** (Mock Filter):"

                else:
                    response_text = "Ch∆∞a hi·ªÉu c√¢u l·ªánh (Mock API). Th·ª≠: 'Top doanh thu', 'ƒê·ªët ti·ªÅn'."
            except Exception as e:
                response_text = f"L·ªói th·ª±c thi: {e}"
        else:
            response_text = "Ch∆∞a c√≥ d·ªØ li·ªáu g·ªëc."

        # 4. Final Render
        msg_placeholder.markdown(response_text)
        if response_df is not None:
            st.dataframe(response_df, height=200)
            st.session_state.last_active_df = response_df
        
        # Save history
        msg_obj = {"role": "assistant", "content": response_text}
        if response_df is not None:
            msg_obj["data"] = response_df
        st.session_state.messages.append(msg_obj)
        
        # Rerun to show buttons
        st.rerun()